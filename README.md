# ğŸ§  Conversational Red Teaming Casebook

Welcome to my personal casebook for testing and breaking AI chatbots through **language, logic, and psychological tactics** â€” no coding or jailbreaks involved.

I specialize in a form of behavioral red teaming where I test the limits, ethics, and reasoning of language models through conversation alone.

---

## ğŸ§ª What You'll Find Here

Each folder documents a different AI chatbot Iâ€™ve tested, including:

- ğŸ§  **Tactics used** (social pressure, framing, value baiting, contradictions)
- ğŸ—£ï¸ **Conversation logs** or notes on behavior
- ğŸ“· **Screenshots** as proof of failures or successful manipulation
- ğŸ“ Reflections on how the bot handled edge cases

This is a living research project built from my passion for AI safety and conversational behavior.

---

## ğŸ§ About Me

Iâ€™m a 17-year-old trucking student in Sweden. I started doing this for fun, and now treat it as serious behavioral testing. I donâ€™t know how to code (yet), but I know how to push chatbots until they show cracks.

If you're a researcher, developer, or AI safety professional â€” feel free to reach out or send me bots to test.

---

ğŸ“¬ **Contact / Challenges / Feedback?**  
Open an issue in this repo or DM me via GitHub.
